import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import altair as alt
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from matplotlib.ticker import FuncFormatter

# --- Streamlit Page Configuration ---
st.set_page_config(page_title="SNIES Anal√≠tica Completa", layout="wide")

# --- URLs for Data ---
URL_PROGRAMAS = "https://raw.githubusercontent.com/JulianTorrest/SNIES-COLOMBIA/main/Programas.csv"
URL_INSTITUCIONES = "https://raw.githubusercontent.com/JulianTorrest/SNIES-COLOMBIA/main/Instituciones.csv"

# --- Data Loading Function ---
@st.cache_data
def cargar_datos():
    """Loads program and institution data from GitHub URLs."""
    df_programas = pd.read_csv(URL_PROGRAMAS)
    df_instituciones = pd.read_csv(URL_INSTITUCIONES)
    return df_programas, df_instituciones

# --- Data Cleaning Function ---
def limpiar_datos(df):
    """Fills missing values in DataFrame: 'object' columns with 'No informado', others with median."""
    df_copy = df.copy() # Work on a copy to avoid modifying original cached data
    for col in df_copy.columns:
        if df_copy[col].dtype == 'object':
            df_copy[col] = df_copy[col].fillna("No informado")
        else:
            df_copy[col] = df_copy[col].fillna(df_copy[col].median(numeric_only=True))
    return df_copy

# --- KPI Functions ---
def kpi_avanzado_programas(df):
    """Displays advanced KPIs for programs."""
    st.markdown("### üìä An√°lisis Avanzado de KPIs para Programas")

    st.subheader("M√©tricas Clave de Programas")
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("N√∫mero Total de Programas", df.shape[0])
    with col2:
        if "N√öMERO_CR√âDITOS" in df.columns:
            avg_creditos = df["N√öMERO_CR√âDITOS"].mean()
            st.metric("Promedio de Cr√©ditos por Programa", f"{avg_creditos:.2f}")
        else:
            st.warning("Columna 'N√öMERO_CR√âDITOS' no encontrada.")
    with col3:
        if "COSTO_MATR√çCULA_ESTUD_NUEVOS" in df.columns:
            avg_matricula = df['COSTO_MATR√çCULA_ESTUD_NUEVOS'].mean()
            st.metric("Costo Promedio de Matr√≠cula", f"${avg_matricula:,.0f}")
        else:
            st.warning("Columna 'COSTO_MATR√çCULA_ESTUD_NUEVOS' no encontrada.")

    st.subheader("Distribuciones Clave")

    # Distribution by Nivel Acad√©mico
    if "NIVEL_ACAD√âMICO" in df.columns:
        st.write("#### Distribuci√≥n de Programas por Nivel Acad√©mico")
        nivel_counts = df["NIVEL_ACAD√âMICO"].value_counts().reset_index()
        nivel_counts.columns = ["Nivel Acad√©mico", "Cantidad"]
        fig = px.bar(nivel_counts, x="Nivel Acad√©mico", y="Cantidad", title="Programas por Nivel Acad√©mico")
        st.plotly_chart(fig, use_container_width=True)
    else:
        st.warning("Columna 'NIVEL_ACAD√âMICO' no encontrada para KPI.")

    # Distribution by Modalidad
    if "MODALIDAD" in df.columns:
        st.write("#### Distribuci√≥n de Programas por Modalidad")
        modalidad_counts = df["MODALIDAD"].value_counts().reset_index()
        modalidad_counts.columns = ["Modalidad", "Cantidad"]
        fig = px.pie(modalidad_counts, names="Modalidad", values="Cantidad", title="Programas por Modalidad")
        st.plotly_chart(fig, use_container_width=True)
    else:
        st.warning("Columna 'MODALIDAD' no encontrada para KPI.")

    st.info("üí° **M√°s KPIs:** Aqu√≠ se podr√≠an a√±adir an√°lisis de 'PERIODICIDAD_ADMISIONES', 'SECTOR', o '√ÅREA_DE_CONOCIMIENTO'.")

def kpi_avanzado_instituciones(df):
    """Displays advanced KPIs for institutions."""
    st.markdown("### üèõÔ∏è An√°lisis Avanzado de KPIs para Instituciones")

    st.subheader("M√©tricas Clave de Instituciones")
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("N√∫mero Total de Instituciones", df.shape[0])
    with col2:
        if "PROGRAMAS_VIGENTES" in df.columns:
            avg_programas = df["PROGRAMAS_VIGENTES"].mean()
            st.metric("Promedio de Programas por Instituci√≥n", f"{avg_programas:.0f}")
        else:
            st.warning("Columna 'PROGRAMAS_VIGENTES' no encontrada.")
    with col3:
        if "ACREDITADA_ALTA_CALIDAD" in df.columns:
            acreditadas_count = df[df["ACREDITADA_ALTA_CALIDAD"] == 'SI'].shape[0]
            st.metric("Instituciones Acreditadas (Alta Calidad)", acreditadas_count)
        else:
            st.warning("Columna 'ACREDITADA_ALTA_CALIDAD' no encontrada.")

    st.subheader("Distribuciones Clave")

    # Distribution by Naturaleza Jur√≠dica
    if "NATURALEZA_JUR√çDICA" in df.columns:
        st.write("#### Distribuci√≥n de Instituciones por Naturaleza Jur√≠dica")
        juridica_counts = df["NATURALEZA_JUR√çDICA"].value_counts().reset_index()
        juridica_counts.columns = ["Naturaleza Jur√≠dica", "Cantidad"]
        fig = px.bar(juridica_counts, x="Naturaleza Jur√≠dica", y="Cantidad", title="Instituciones por Naturaleza Jur√≠dica")
        st.plotly_chart(fig, use_container_width=True)
    else:
        st.warning("Columna 'NATURALEZA_JUR√çDICA' no encontrada para KPI.")

    # Distribution by Sector
    if "SECTOR" in df.columns:
        st.write("#### Distribuci√≥n de Instituciones por Sector")
        sector_counts = df["SECTOR"].value_counts().reset_index()
        sector_counts.columns = ["Sector", "Cantidad"]
        fig = px.pie(sector_counts, names="Sector", values="Cantidad", title="Instituciones por Sector")
        st.plotly_chart(fig, use_container_width=True)
    else:
        st.warning("Columna 'SECTOR' no encontrada para KPI.")

    st.info("üí° **M√°s KPIs:** Se podr√≠a analizar la distribuci√≥n por 'CAR√ÅCTER_ACAD√âMICO' o por 'DEPARTAMENTO_DOMICILIO'.")


# --- Machine Learning Functions (Placeholders) ---
def ml_programas(df):
    """Placeholder for Machine Learning models for programs."""
    st.markdown("### ü§ñ Modelos de Machine Learning para Programas")
    st.info("""
        Aqu√≠ se aplicar√≠an modelos de Machine Learning.
        
        **Ejemplos de Modelos a Implementar:**
        1.  **Clustering (K-Means):** Para agrupar programas similares por `N√öMERO_CR√âDITOS`, `COSTO_MATR√çCULA_ESTUD_NUEVOS`.
        2.  **Regresi√≥n (Random Forest Regressor):** Para predecir `COSTO_MATR√çCULA_ESTUD_NUEVOS` basado en caracter√≠sticas del programa.
        3.  **Clasificaci√≥n (Decision Tree):** Para clasificar el `NIVEL_ACAD√âMICO` de un programa.
        """)
    st.write("---")
    st.subheader("Ejemplo: Clustering de Programas (K-Means)")
    df_num = df[["N√öMERO_CR√âDITOS", "COSTO_MATR√çCULA_ESTUD_NUEVOS"]].dropna() if "N√öMERO_CR√âDITOS" in df.columns and "COSTO_MATR√çCULA_ESTUD_NUEVOS" in df.columns else pd.DataFrame()

    if df_num.empty or df_num.shape[1] < 2:
        st.warning("Se necesitan las columnas 'N√öMERO_CR√âDITOS' y 'COSTO_MATR√çCULA_ESTUD_NUEVOS' y datos suficientes para este ejemplo de clustering.")
        return

    scaler = StandardScaler()
    df_scaled = scaler.fit_transform(df_num)

    k = st.slider("N√∫mero de clusters (Programas):", 2, min(10, df_scaled.shape[0] // 2), 3) # Ensure k is not too large
    try:
        model = KMeans(n_clusters=k, n_init="auto", random_state=42)
        clusters = model.fit_predict(df_scaled)
        df_num["CLUSTER"] = clusters

        fig = px.scatter(df_num, x="N√öMERO_CR√âDITOS", y="COSTO_MATR√çCULA_ESTUD_NUEVOS",
                         color=df_num["CLUSTER"].astype(str),
                         title=f"Clusters de Programas (K={k})",
                         hover_data=df_num.columns)
        st.plotly_chart(fig, use_container_width=True)
        st.write("Conteo de Programas por Cluster:")
        st.dataframe(df_num["CLUSTER"].value_counts())
    except Exception as e:
        st.error(f"Error al ejecutar el clustering: {e}")

def ml_instituciones(df):
    """Placeholder for Machine Learning models for institutions."""
    st.markdown("### ü§ñ Modelos de Machine Learning para Instituciones")
    st.info("""
        Aqu√≠ se aplicar√≠an modelos de Machine Learning.

        **Ejemplos de Modelos a Implementar:**
        1.  **Clustering (Agglomerative Clustering):** Para agrupar instituciones similares por `PROGRAMAS_VIGENTES`, `SECTOR`.
        2.  **Clasificaci√≥n (Logistic Regression):** Para predecir si una instituci√≥n est√° `ACREDITADA_ALTA_CALIDAD`.
        3.  **NLP (Topic Modeling):** Para extraer temas de la columna `MISI√ìN`.
        """)
    st.write("---")
    st.subheader("Ejemplo: Clasificaci√≥n de Instituciones (Acreditaci√≥n)")
    if "ACREDITADA_ALTA_CALIDAD" not in df.columns or "PROGRAMAS_VIGENTES" not in df.columns or "SECTOR" not in df.columns:
        st.warning("Se necesitan las columnas 'ACREDITADA_ALTA_CALIDAD', 'PROGRAMAS_VIGENTES' y 'SECTOR' para este ejemplo de clasificaci√≥n.")
        return

    from sklearn.model_selection import train_test_split
    from sklearn.ensemble import RandomForestClassifier
    from sklearn.metrics import accuracy_score

    df_ml = df.copy()
    # Basic Feature Engineering and One-Hot Encoding
    df_ml['SECTOR_encoded'] = df_ml['SECTOR'].astype('category').cat.codes
    df_ml['NATURALEZA_JUR√çDICA_encoded'] = df_ml['NATURALEZA_JUR√çDICA'].astype('category').cat.codes

    features = ['PROGRAMAS_VIGENTES', 'SECTOR_encoded', 'NATURALEZA_JUR√çDICA_encoded']
    target = 'ACREDITADA_ALTA_CALIDAD'

    # Filter out 'No informado' or NaN values in target if they exist
    df_ml = df_ml[df_ml[target].isin(['SI', 'NO'])]

    if df_ml.empty or not all(col in df_ml.columns for col in features):
        st.warning("Datos insuficientes o columnas requeridas no presentes para el ejemplo de clasificaci√≥n.")
        return

    X = df_ml[features].dropna()
    y = df_ml.loc[X.index, target] # Align y with X's index after dropping NA

    if X.empty or len(X) < 2:
        st.warning("No hay suficientes datos para entrenar el modelo despu√©s de la preparaci√≥n.")
        return

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)

    model = RandomForestClassifier(random_state=42)
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)

    st.write(f"Precisi√≥n del Modelo de Clasificaci√≥n (Random Forest): **{accuracy:.2f}**")
    st.write("Caracter√≠sticas de importancia:")
    feature_importances = pd.Series(model.feature_importances_, index=features).sort_values(ascending=False)
    st.bar_chart(feature_importances)


# --- Advanced Visualization Function ---
def visualizacion_avanzada(df):
    """Allows interactive visualization based on user selection."""
    st.markdown("### üìà Visualizaci√≥n Interactiva")

    cualitativas = df.select_dtypes(include='object').columns.tolist()
    cuantitativas = df.select_dtypes(include='number').columns.tolist()

    if not cualitativas or not cuantitativas:
        st.warning("No hay suficientes columnas cualitativas o cuantitativas para esta visualizaci√≥n.")
        return

    # User selections for visualization
    selected_x = st.selectbox("Selecciona Variable para Eje X (Cualitativa):", cualitativas)
    selected_y = st.selectbox("Selecciona Variable para Eje Y (Cuantitativa):", cuantitativas)
    chart_type = st.selectbox("Selecciona Tipo de Gr√°fico:", ["Barras", "Boxplot", "Viol√≠n", "Histograma", "Dispersi√≥n"])

    if chart_type == "Barras":
        st.write(f"#### Conteo o Suma de '{selected_y}' por '{selected_x}'")
        aggregation_option = st.selectbox("Selecciona Operaci√≥n de Agregaci√≥n:", ["Conteo", "Suma", "Promedio"])
        if aggregation_option == "Conteo":
            agg_df = df[selected_x].value_counts().reset_index()
            agg_df.columns = [selected_x, 'Cantidad']
            fig = px.bar(agg_df, x=selected_x, y='Cantidad', title=f"Conteo de '{selected_x}'")
        else:
            agg_df = df.groupby(selected_x)[selected_y].agg(aggregation_option.lower()).reset_index()
            agg_df.columns = [selected_x, 'Valor Agregado']
            fig = px.bar(agg_df, x=selected_x, y='Valor Agregado', title=f"{aggregation_option} de '{selected_y}' por '{selected_x}'")
        st.plotly_chart(fig, use_container_width=True)

    elif chart_type == "Boxplot":
        st.write(f"#### Boxplot de '{selected_y}' por '{selected_x}'")
        fig = px.box(df, x=selected_x, y=selected_y, title=f"Distribuci√≥n de '{selected_y}' por '{selected_x}'")
        st.plotly_chart(fig, use_container_width=True)

    elif chart_type == "Viol√≠n":
        st.write(f"#### Violin Plot de '{selected_y}' por '{selected_x}'")
        fig = px.violin(df, x=selected_x, y=selected_y, box=True, title=f"Densidad de '{selected_y}' por '{selected_x}'")
        st.plotly_chart(fig, use_container_width=True)

    elif chart_type == "Histograma":
        st.write(f"#### Histograma de '{selected_y}' (Coloreado por '{selected_x}')")
        fig = px.histogram(df, x=selected_y, color=selected_x, title=f"Distribuci√≥n de '{selected_y}' por '{selected_x}'")
        st.plotly_chart(fig, use_container_width=True)

    elif chart_type == "Dispersi√≥n":
        st.write(f"#### Gr√°fico de Dispersi√≥n entre '{selected_y}' y '{selected_x}'")
        color_option = st.selectbox("Colorear por (Opcional):", ["Ninguno"] + cualitativas)
        if color_option == "Ninguno":
            fig = px.scatter(df, x=selected_x, y=selected_y, title=f"Relaci√≥n entre '{selected_x}' y '{selected_y}'")
        else:
            fig = px.scatter(df, x=selected_x, y=selected_y, color=color_option, title=f"Relaci√≥n entre '{selected_x}' y '{selected_y}' (Coloreado por {color_option})")
        st.plotly_chart(fig, use_container_width=True)

    st.info("üí° **M√°s Visualizaciones:** Se pueden a√±adir gr√°ficos de torta, treemaps, sunburst, o heatmaps para explorar m√°s a fondo los datos.")


# --- Main EDA Function with Tabs ---
def eda_completo(nombre_df, df_original):
    """
    Performs Exploratory Data Analysis (EDA) in a modular way using Streamlit tabs.
    Args:
        nombre_df (str): Name of the DataFrame (e.g., "Programas", "Instituciones").
        df_original (pd.DataFrame): The original DataFrame to analyze.
    """
    # Create a working copy of the DataFrame to apply cleaning without affecting the cached original
    df_working = df_original.copy()

    tabs = st.tabs(["üìÑ Datos", "üßº Limpieza", "üìà Visualizaci√≥n", "üìä KPIs", "ü§ñ ML"])

    with tabs[0]:
        st.subheader(f"Vista Previa de {nombre_df}")
        st.dataframe(df_working.head())
        st.write(f"üìã **Tipos de Datos en {nombre_df}:**")
        st.dataframe(df_working.dtypes) # Use st.dataframe for better readability
        st.write(f"üîç **Valores Nulos por Columna en {nombre_df} (Antes de Limpieza):**")
        st.dataframe(df_working.isnull().sum().reset_index(name='Nulos').rename(columns={'index': 'Columna'})) # Better display of nulls

    with tabs[1]:
        st.subheader(f"Limpieza de Datos para {nombre_df}")
        st.info("Aplicando la estrategia de limpieza: Rellenar nulos de tipo 'object' con 'No informado' y nulos num√©ricos con la mediana.")
        df_cleaned = limpiar_datos(df_working) # Clean the working copy
        st.success(f"Datos de {nombre_df} limpiados correctamente.")
        st.subheader(f"Valores Nulos Despu√©s de la Limpieza en {nombre_df}:")
        st.dataframe(df_cleaned.isnull().sum().reset_index(name='Nulos').rename(columns={'index': 'Columna'})) # Display nulls after cleaning
        st.subheader(f"Vista Previa de {nombre_df} Despu√©s de la Limpieza:")
        st.dataframe(df_cleaned.head())
        # Update the working DataFrame to the cleaned version for subsequent tabs
        df_working = df_cleaned

    with tabs[2]:
        # Visualizations should use the cleaned data
        visualizacion_avanzada(df_working)

    with tabs[3]:
        # KPIs should use the cleaned data
        if nombre_df == "Programas":
            kpi_avanzado_programas(df_working)
        else:
            kpi_avanzado_instituciones(df_working)

    with tabs[4]:
        # ML models should use the cleaned data
        if nombre_df == "Programas":
            ml_programas(df_working)
        else:
            ml_instituciones(df_working)

# --- Main Streamlit Application Entry Point ---
st.title("üìä SNIES - Anal√≠tica de Programas e Instituciones")

# Load data once and cache it
df_programas, df_instituciones = cargar_datos()

# Main navigation radio button
opcion = st.radio("Selecciona el m√≥dulo a explorar:", ["Programas", "Instituciones"])

# Route to the appropriate EDA module based on user selection
if opcion == "Programas":
    eda_completo("Programas", df_programas)
else:
    eda_completo("Instituciones", df_instituciones)
